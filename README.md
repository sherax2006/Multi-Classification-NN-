# Multi-Classification Neural Network

This repository demonstrates the implementation of a **multi-class neural network from scratch in Python**, using **NumPy**. It is designed for **educational purposes** to help you understand the core concepts of **feedforward** and **backpropagation** for classification tasks.

---

## Features
1. **Dynamic number of output neurons**: The number of neurons in the output layer is automatically set based on the number of unique classes in the dataset.  
2. **Feedforward propagation**: Computes the network output using matrix multiplication and weights.  
3. **Softmax activation function**: Used in the output layer for multi-class probability prediction.  
4. **Cross-entropy loss**: Measures the difference between predicted probabilities and true labels.  
5. **Backpropagation**: Computes gradients of weights and biases to update the network.  
6. **Gradient Descent optimizer**: Updates weights and biases iteratively to minimize the loss.  
7. **Validation**: Includes calculation of validation loss and accuracy.

---

## Learning Outcomes
By following this project, you will gain:

1. A clear understanding of **feedforward propagation** in neural networks.  
2. Step-by-step comprehension of **backpropagation** and gradient calculation.  
3. Experience implementing **multi-class classification** using **softmax** and **cross-entropy**.  
4. Insight into **weight updates** using **Gradient Descent**.

---

## Author
**M Sheraz Rana**  
[GitHub Profile](https://github.com/sherax2006)
